Experiment Summary.
This experiment is based on the pattern found in the coeficient of variation.
The limit used for this experiment is: 300
Model: meta-llama/Meta-Llama-3-8B
Dataset: wikitext2
Source for Vector-Cut: wikitext2
Evaluated on: ['arc_easy', 'hellaswag', 'winogrande', 'arc_challenge', 'piqa', 'gsm8k_cot']%
CUDA Device: cuda:0
Vector: 0.7718545654265384 0.7703350841343449 0.7774971524694532 0.789480405516778 0.7885866681916415 0.7902172878465734 0.7840426292867366 0.7842170622043441 0.7815744783000037 0.7870328977667728 0.7858136708265474 0.7869711340826666 0.7830286795307925 0.7834222741693648 0.7832385437005959 0.7849694966930585 0.7863103286971396 0.7855211393577833 0.7859798975312271 0.7838776570766343 0.7866032575877824 0.7835758969802465 0.7861066250588533 0.7818700734047256 0.7855140705100239 0.7835559203312974 0.7878234765435443 0.7827323578872225 0.786661123293898 0.7845421153502381 0.7885184235786918 0.7851191457743905 0.7883121982373014 0.7875409112128136 0.7902639086795668 0.7878809360798108 0.7902751090832493 0.788554322487008 0.7886827150018514 0.7877879849674371 0.7872858354321548 0.787056372992329 0.7866447796855331 0.7860817507589004 0.7859825744001883 0.7852254952085107 0.7837415137521667 0.7829785693406648 0.780616782029149 0.7806339041108127 0.7785263339494131 0.7784173943007873 0.7769423766346264 0.7757122165506934 0.7738040366762994 0.7738824320340881 0.7719033709600711 0.7710799305507171 0.7691008379346381 0.7687999883175118 0.7668250114685589 0.7663556613857762 0.7650262284536474 0.7632967756346611 0.7613622050325072


n
Variation 0.0%, adding to the mean: 0.3, Average accuracy: {'gsm8k_cot': {'exact_match,strict-match': 0.02, 'exact_match_stderr,strict-match': 0.008096409047527352, 'exact_match,flexible-extract': 0.013333333333333334, 'exact_match_stderr,flexible-extract': 0.00663313753541497, 'alias': 'gsm8k_cot'}, 'piqa': {'acc,none': 0.5633333333333334, 'acc_stderr,none': 0.028682840061780197, 'acc_norm,none': 0.5466666666666666, 'acc_norm_stderr,none': 0.028789526978043094, 'alias': 'piqa'}, 'arc_challenge': {'acc,none': 0.21, 'acc_stderr,none': 0.023555243542102446, 'acc_norm,none': 0.25333333333333335, 'acc_norm_stderr,none': 0.025152082937711914, 'alias': 'arc_challenge'}, 'winogrande': {'acc,none': 0.55, 'acc_stderr,none': 0.028770804599878935, 'alias': 'winogrande'}, 'hellaswag': {'acc,none': 0.39666666666666667, 'acc_stderr,none': 0.028291496425144967, 'acc_norm,none': 0.49666666666666665, 'acc_norm_stderr,none': 0.028915104019025518, 'alias': 'hellaswag'}, 'arc_easy': {'acc,none': 0.49333333333333335, 'acc_stderr,none': 0.028913176195480325, 'acc_norm,none': 0.41, 'acc_norm_stderr,none': 0.028443454437435168, 'alias': 'arc_easy'}}

Variation 0.02%, adding to the mean: 0.27999999999999997, Average accuracy: {'gsm8k_cot': {'exact_match,strict-match': 0.01, 'exact_match_stderr,strict-match': 0.005754160919975807, 'exact_match,flexible-extract': 0.02, 'exact_match_stderr,flexible-extract': 0.008096409047527354, 'alias': 'gsm8k_cot'}, 'piqa': {'acc,none': 0.5633333333333334, 'acc_stderr,none': 0.0286828400617802, 'acc_norm,none': 0.55, 'acc_norm_stderr,none': 0.028770804599878942, 'alias': 'piqa'}, 'arc_challenge': {'acc,none': 0.19666666666666666, 'acc_stderr,none': 0.02298675559401021, 'acc_norm,none': 0.26, 'acc_norm_stderr,none': 0.025366873297069235, 'alias': 'arc_challenge'}, 'winogrande': {'acc,none': 0.55, 'acc_stderr,none': 0.028770804599878942, 'alias': 'winogrande'}, 'hellaswag': {'acc,none': 0.3933333333333333, 'acc_stderr,none': 0.028250090846760875, 'acc_norm,none': 0.49333333333333335, 'acc_norm_stderr,none': 0.028913176195480332, 'alias': 'hellaswag'}, 'arc_easy': {'acc,none': 0.48333333333333334, 'acc_stderr,none': 0.02889967782985889, 'acc_norm,none': 0.41333333333333333, 'acc_norm_stderr,none': 0.02847805520731585, 'alias': 'arc_easy'}}

Variation 0.04%, adding to the mean: 0.26, Average accuracy: {'gsm8k_cot': {'exact_match,strict-match': 0.02, 'exact_match_stderr,strict-match': 0.008096409047527352, 'exact_match,flexible-extract': 0.023333333333333334, 'exact_match_stderr,flexible-extract': 0.008730235947285767, 'alias': 'gsm8k_cot'}, 'piqa': {'acc,none': 0.56, 'acc_stderr,none': 0.028706798281217746, 'acc_norm,none': 0.56, 'acc_norm_stderr,none': 0.028706798281217742, 'alias': 'piqa'}, 'arc_challenge': {'acc,none': 0.21, 'acc_stderr,none': 0.023555243542102446, 'acc_norm,none': 0.26, 'acc_norm_stderr,none': 0.025366873297069235, 'alias': 'arc_challenge'}, 'winogrande': {'acc,none': 0.5733333333333334, 'acc_stderr,none': 0.02860305092961844, 'alias': 'winogrande'}, 'hellaswag': {'acc,none': 0.39, 'acc_stderr,none': 0.028207307101406273, 'acc_norm,none': 0.48333333333333334, 'acc_norm_stderr,none': 0.02889967782985889, 'alias': 'hellaswag'}, 'arc_easy': {'acc,none': 0.49, 'acc_stderr,none': 0.028909962870561686, 'acc_norm,none': 0.41333333333333333, 'acc_norm_stderr,none': 0.028478055207315858, 'alias': 'arc_easy'}}

Variation 0.06%, adding to the mean: 0.24, Average accuracy: {'gsm8k_cot': {'exact_match,strict-match': 0.013333333333333334, 'exact_match_stderr,strict-match': 0.006633137535414967, 'exact_match,flexible-extract': 0.02666666666666667, 'exact_match_stderr,flexible-extract': 0.009317074546885752, 'alias': 'gsm8k_cot'}, 'piqa': {'acc,none': 0.5833333333333334, 'acc_stderr,none': 0.028511310643917574, 'acc_norm,none': 0.58, 'acc_norm_stderr,none': 0.028543225449544848, 'alias': 'piqa'}, 'arc_challenge': {'acc,none': 0.22, 'acc_stderr,none': 0.02395648228514077, 'acc_norm,none': 0.26, 'acc_norm_stderr,none': 0.025366873297069235, 'alias': 'arc_challenge'}, 'winogrande': {'acc,none': 0.5833333333333334, 'acc_stderr,none': 0.02851131064391757, 'alias': 'winogrande'}, 'hellaswag': {'acc,none': 0.37333333333333335, 'acc_stderr,none': 0.027972487412192493, 'acc_norm,none': 0.47333333333333333, 'acc_norm_stderr,none': 0.028874592695089598, 'alias': 'hellaswag'}, 'arc_easy': {'acc,none': 0.49, 'acc_stderr,none': 0.02890996287056168, 'acc_norm,none': 0.42333333333333334, 'acc_norm_stderr,none': 0.028573804116352325, 'alias': 'arc_easy'}}

Variation 0.08%, adding to the mean: 0.21999999999999997, Average accuracy: {'gsm8k_cot': {'exact_match,strict-match': 0.02, 'exact_match_stderr,strict-match': 0.008096409047527352, 'exact_match,flexible-extract': 0.03333333333333333, 'exact_match_stderr,flexible-extract': 0.01038107073021663, 'alias': 'gsm8k_cot'}, 'piqa': {'acc,none': 0.59, 'acc_stderr,none': 0.028443454437435168, 'acc_norm,none': 0.5566666666666666, 'acc_norm_stderr,none': 0.028729443073159968, 'alias': 'piqa'}, 'arc_challenge': {'acc,none': 0.22, 'acc_stderr,none': 0.02395648228514077, 'acc_norm,none': 0.2733333333333333, 'acc_norm_stderr,none': 0.025773792282785972, 'alias': 'arc_challenge'}, 'winogrande': {'acc,none': 0.5866666666666667, 'acc_stderr,none': 0.028478055207315858, 'alias': 'winogrande'}, 'hellaswag': {'acc,none': 0.38666666666666666, 'acc_stderr,none': 0.028163138908196845, 'acc_norm,none': 0.48, 'acc_norm_stderr,none': 0.028892604740584655, 'alias': 'hellaswag'}, 'arc_easy': {'acc,none': 0.47, 'acc_stderr,none': 0.02886365132641709, 'acc_norm,none': 0.4266666666666667, 'acc_norm_stderr,none': 0.028603050929618436, 'alias': 'arc_easy'}}

Variation 0.1%, adding to the mean: 0.19999999999999998, Average accuracy: {'gsm8k_cot': {'exact_match,strict-match': 0.023333333333333334, 'exact_match_stderr,strict-match': 0.008730235947285765, 'exact_match,flexible-extract': 0.03666666666666667, 'exact_match_stderr,flexible-extract': 0.010868970626620969, 'alias': 'gsm8k_cot'}, 'piqa': {'acc,none': 0.5633333333333334, 'acc_stderr,none': 0.0286828400617802, 'acc_norm,none': 0.55, 'acc_norm_stderr,none': 0.02877080459987894, 'alias': 'piqa'}, 'arc_challenge': {'acc,none': 0.22, 'acc_stderr,none': 0.02395648228514077, 'acc_norm,none': 0.24333333333333335, 'acc_norm_stderr,none': 0.02481518457232592, 'alias': 'arc_challenge'}, 'winogrande': {'acc,none': 0.5766666666666667, 'acc_stderr,none': 0.028573804116352332, 'alias': 'winogrande'}, 'hellaswag': {'acc,none': 0.38333333333333336, 'acc_stderr,none': 0.028117579742899083, 'acc_norm,none': 0.49, 'acc_norm_stderr,none': 0.02890996287056168, 'alias': 'hellaswag'}, 'arc_easy': {'acc,none': 0.4766666666666667, 'acc_stderr,none': 0.028884243402038653, 'acc_norm,none': 0.42333333333333334, 'acc_norm_stderr,none': 0.02857380411635233, 'alias': 'arc_easy'}}

Variation 0.12%, adding to the mean: 0.18, Average accuracy: {'gsm8k_cot': {'exact_match,strict-match': 0.013333333333333334, 'exact_match_stderr,strict-match': 0.006633137535414963, 'exact_match,flexible-extract': 0.02666666666666667, 'exact_match_stderr,flexible-extract': 0.009317074546885762, 'alias': 'gsm8k_cot'}, 'piqa': {'acc,none': 0.5766666666666667, 'acc_stderr,none': 0.02857380411635233, 'acc_norm,none': 0.5433333333333333, 'acc_norm_stderr,none': 0.028806947219396126, 'alias': 'piqa'}, 'arc_challenge': {'acc,none': 0.21333333333333335, 'acc_stderr,none': 0.02369131349654082, 'acc_norm,none': 0.25333333333333335, 'acc_norm_stderr,none': 0.025152082937711914, 'alias': 'arc_challenge'}, 'winogrande': {'acc,none': 0.58, 'acc_stderr,none': 0.028543225449544844, 'alias': 'winogrande'}, 'hellaswag': {'acc,none': 0.37666666666666665, 'acc_stderr,none': 0.028022261151265607, 'acc_norm,none': 0.47333333333333333, 'acc_norm_stderr,none': 0.028874592695089598, 'alias': 'hellaswag'}, 'arc_easy': {'acc,none': 0.47333333333333333, 'acc_stderr,none': 0.028874592695089598, 'acc_norm,none': 0.41, 'acc_norm_stderr,none': 0.028443454437435168, 'alias': 'arc_easy'}}

Variation 0.14%, adding to the mean: 0.15999999999999998, Average accuracy: {'gsm8k_cot': {'exact_match,strict-match': 0.006666666666666667, 'exact_match_stderr,strict-match': 0.004706155586970106, 'exact_match,flexible-extract': 0.02, 'exact_match_stderr,flexible-extract': 0.008096409047527354, 'alias': 'gsm8k_cot'}, 'piqa': {'acc,none': 0.58, 'acc_stderr,none': 0.028543225449544848, 'acc_norm,none': 0.55, 'acc_norm_stderr,none': 0.028770804599878942, 'alias': 'piqa'}, 'arc_challenge': {'acc,none': 0.22, 'acc_stderr,none': 0.02395648228514077, 'acc_norm,none': 0.26666666666666666, 'acc_norm_stderr,none': 0.025574048533225646, 'alias': 'arc_challenge'}, 'winogrande': {'acc,none': 0.5933333333333334, 'acc_stderr,none': 0.028407503418366627, 'alias': 'winogrande'}, 'hellaswag': {'acc,none': 0.36666666666666664, 'acc_stderr,none': 0.027868673283383924, 'acc_norm,none': 0.47, 'acc_norm_stderr,none': 0.02886365132641709, 'alias': 'hellaswag'}, 'arc_easy': {'acc,none': 0.44333333333333336, 'acc_stderr,none': 0.02872944307315997, 'acc_norm,none': 0.4, 'acc_norm_stderr,none': 0.028331529878993063, 'alias': 'arc_easy'}}

Variation 0.16%, adding to the mean: 0.13999999999999999, Average accuracy: {'gsm8k_cot': {'exact_match,strict-match': 0.0033333333333333335, 'exact_match_stderr,strict-match': 0.0033333333333333275, 'exact_match,flexible-extract': 0.02666666666666667, 'exact_match_stderr,flexible-extract': 0.00931707454688576, 'alias': 'gsm8k_cot'}, 'piqa': {'acc,none': 0.5766666666666667, 'acc_stderr,none': 0.02857380411635232, 'acc_norm,none': 0.5566666666666666, 'acc_norm_stderr,none': 0.028729443073159965, 'alias': 'piqa'}, 'arc_challenge': {'acc,none': 0.22, 'acc_stderr,none': 0.02395648228514077, 'acc_norm,none': 0.25666666666666665, 'acc_norm_stderr,none': 0.025260441987310478, 'alias': 'arc_challenge'}, 'winogrande': {'acc,none': 0.5433333333333333, 'acc_stderr,none': 0.02880694721939613, 'alias': 'winogrande'}, 'hellaswag': {'acc,none': 0.36666666666666664, 'acc_stderr,none': 0.027868673283383917, 'acc_norm,none': 0.45, 'acc_norm_stderr,none': 0.02877080459987894, 'alias': 'hellaswag'}, 'arc_easy': {'acc,none': 0.4533333333333333, 'acc_stderr,none': 0.028789526978043094, 'acc_norm,none': 0.39666666666666667, 'acc_norm_stderr,none': 0.028291496425144967, 'alias': 'arc_easy'}}

Variation 0.18%, adding to the mean: 0.12, Average accuracy: {'gsm8k_cot': {'exact_match,strict-match': 0.0, 'exact_match_stderr,strict-match': 0.0, 'exact_match,flexible-extract': 0.013333333333333334, 'exact_match_stderr,flexible-extract': 0.006633137535414942, 'alias': 'gsm8k_cot'}, 'piqa': {'acc,none': 0.5733333333333334, 'acc_stderr,none': 0.028603050929618443, 'acc_norm,none': 0.5533333333333333, 'acc_norm_stderr,none': 0.028750777541066686, 'alias': 'piqa'}, 'arc_challenge': {'acc,none': 0.22666666666666666, 'acc_stderr,none': 0.024212609617951898, 'acc_norm,none': 0.25333333333333335, 'acc_norm_stderr,none': 0.025152082937711914, 'alias': 'arc_challenge'}, 'winogrande': {'acc,none': 0.55, 'acc_stderr,none': 0.02877080459987894, 'alias': 'winogrande'}, 'hellaswag': {'acc,none': 0.36, 'acc_stderr,none': 0.02775911673437956, 'acc_norm,none': 0.43333333333333335, 'acc_norm_stderr,none': 0.028657565120703117, 'alias': 'hellaswag'}, 'arc_easy': {'acc,none': 0.4533333333333333, 'acc_stderr,none': 0.028789526978043094, 'acc_norm,none': 0.4033333333333333, 'acc_norm_stderr,none': 0.028370197016959937, 'alias': 'arc_easy'}}

Variation 0.2%, adding to the mean: 0.09999999999999998, Average accuracy: {'gsm8k_cot': {'exact_match,strict-match': 0.0, 'exact_match_stderr,strict-match': 0.0, 'exact_match,flexible-extract': 0.02, 'exact_match_stderr,flexible-extract': 0.008096409047527356, 'alias': 'gsm8k_cot'}, 'piqa': {'acc,none': 0.57, 'acc_stderr,none': 0.028630969970847474, 'acc_norm,none': 0.55, 'acc_norm_stderr,none': 0.028770804599878935, 'alias': 'piqa'}, 'arc_challenge': {'acc,none': 0.21666666666666667, 'acc_stderr,none': 0.023825046699671854, 'acc_norm,none': 0.24333333333333335, 'acc_norm_stderr,none': 0.02481518457232592, 'alias': 'arc_challenge'}, 'winogrande': {'acc,none': 0.5366666666666666, 'acc_stderr,none': 0.028837890554337258, 'alias': 'winogrande'}, 'hellaswag': {'acc,none': 0.36, 'acc_stderr,none': 0.027759116734379558, 'acc_norm,none': 0.42333333333333334, 'acc_norm_stderr,none': 0.028573804116352325, 'alias': 'hellaswag'}, 'arc_easy': {'acc,none': 0.44666666666666666, 'acc_stderr,none': 0.02875077754106668, 'acc_norm,none': 0.38333333333333336, 'acc_norm_stderr,none': 0.028117579742899086, 'alias': 'arc_easy'}}

Variation 0.22%, adding to the mean: 0.07999999999999999, Average accuracy: {'gsm8k_cot': {'exact_match,strict-match': 0.0, 'exact_match_stderr,strict-match': 0.0, 'exact_match,flexible-extract': 0.01, 'exact_match_stderr,flexible-extract': 0.005754160919975807, 'alias': 'gsm8k_cot'}, 'piqa': {'acc,none': 0.5566666666666666, 'acc_stderr,none': 0.028729443073159965, 'acc_norm,none': 0.5433333333333333, 'acc_norm_stderr,none': 0.02880694721939613, 'alias': 'piqa'}, 'arc_challenge': {'acc,none': 0.20666666666666667, 'acc_stderr,none': 0.02341679610131764, 'acc_norm,none': 0.22666666666666666, 'acc_norm_stderr,none': 0.024212609617951904, 'alias': 'arc_challenge'}, 'winogrande': {'acc,none': 0.53, 'acc_stderr,none': 0.02886365132641709, 'alias': 'winogrande'}, 'hellaswag': {'acc,none': 0.33666666666666667, 'acc_stderr,none': 0.02732941756218686, 'acc_norm,none': 0.41333333333333333, 'acc_norm_stderr,none': 0.02847805520731585, 'alias': 'hellaswag'}, 'arc_easy': {'acc,none': 0.42333333333333334, 'acc_stderr,none': 0.028573804116352332, 'acc_norm,none': 0.38666666666666666, 'acc_norm_stderr,none': 0.02816313890819685, 'alias': 'arc_easy'}}

Variation 0.24%, adding to the mean: 0.06, Average accuracy: {'gsm8k_cot': {'exact_match,strict-match': 0.0, 'exact_match_stderr,strict-match': 0.0, 'exact_match,flexible-extract': 0.02, 'exact_match_stderr,flexible-extract': 0.008096409047527352, 'alias': 'gsm8k_cot'}, 'piqa': {'acc,none': 0.5333333333333333, 'acc_stderr,none': 0.02885141782764204, 'acc_norm,none': 0.53, 'acc_norm_stderr,none': 0.02886365132641709, 'alias': 'piqa'}, 'arc_challenge': {'acc,none': 0.20333333333333334, 'acc_stderr,none': 0.0232759287496797, 'acc_norm,none': 0.24, 'acc_norm_stderr,none': 0.02469885513168685, 'alias': 'arc_challenge'}, 'winogrande': {'acc,none': 0.51, 'acc_stderr,none': 0.02890996287056168, 'alias': 'winogrande'}, 'hellaswag': {'acc,none': 0.3333333333333333, 'acc_stderr,none': 0.027262027336984386, 'acc_norm,none': 0.3933333333333333, 'acc_norm_stderr,none': 0.028250090846760875, 'alias': 'hellaswag'}, 'arc_easy': {'acc,none': 0.4, 'acc_stderr,none': 0.028331529878993063, 'acc_norm,none': 0.37333333333333335, 'acc_norm_stderr,none': 0.02797248741219249, 'alias': 'arc_easy'}}

Variation 0.26%, adding to the mean: 0.03999999999999998, Average accuracy: {'gsm8k_cot': {'exact_match,strict-match': 0.0, 'exact_match_stderr,strict-match': 0.0, 'exact_match,flexible-extract': 0.016666666666666666, 'exact_match_stderr,flexible-extract': 0.007403535467669025, 'alias': 'gsm8k_cot'}, 'piqa': {'acc,none': 0.5366666666666666, 'acc_stderr,none': 0.02883789055433726, 'acc_norm,none': 0.5266666666666666, 'acc_norm_stderr,none': 0.028874592695089598, 'alias': 'piqa'}, 'arc_challenge': {'acc,none': 0.19666666666666666, 'acc_stderr,none': 0.02298675559401021, 'acc_norm,none': 0.21666666666666667, 'acc_norm_stderr,none': 0.023825046699671854, 'alias': 'arc_challenge'}, 'winogrande': {'acc,none': 0.49333333333333335, 'acc_stderr,none': 0.028913176195480332, 'alias': 'winogrande'}, 'hellaswag': {'acc,none': 0.3233333333333333, 'acc_stderr,none': 0.027050608391385685, 'acc_norm,none': 0.37333333333333335, 'acc_norm_stderr,none': 0.027972487412192493, 'alias': 'hellaswag'}, 'arc_easy': {'acc,none': 0.38666666666666666, 'acc_stderr,none': 0.02816313890819685, 'acc_norm,none': 0.36666666666666664, 'acc_norm_stderr,none': 0.027868673283383914, 'alias': 'arc_easy'}}

Variation 0.28%, adding to the mean: 0.019999999999999962, Average accuracy: {'gsm8k_cot': {'exact_match,strict-match': 0.0, 'exact_match_stderr,strict-match': 0.0, 'exact_match,flexible-extract': 0.01, 'exact_match_stderr,flexible-extract': 0.005754160919975788, 'alias': 'gsm8k_cot'}, 'piqa': {'acc,none': 0.51, 'acc_stderr,none': 0.02890996287056168, 'acc_norm,none': 0.5066666666666667, 'acc_norm_stderr,none': 0.028913176195480332, 'alias': 'piqa'}, 'arc_challenge': {'acc,none': 0.21, 'acc_stderr,none': 0.023555243542102446, 'acc_norm,none': 0.22, 'acc_norm_stderr,none': 0.02395648228514077, 'alias': 'arc_challenge'}, 'winogrande': {'acc,none': 0.49333333333333335, 'acc_stderr,none': 0.028913176195480325, 'alias': 'winogrande'}, 'hellaswag': {'acc,none': 0.30666666666666664, 'acc_stderr,none': 0.026666666666666655, 'acc_norm,none': 0.37666666666666665, 'acc_norm_stderr,none': 0.028022261151265607, 'alias': 'hellaswag'}, 'arc_easy': {'acc,none': 0.39666666666666667, 'acc_stderr,none': 0.028291496425144964, 'acc_norm,none': 0.37333333333333335, 'acc_norm_stderr,none': 0.027972487412192493, 'alias': 'arc_easy'}}

Variation 0.3%, adding to the mean: 0.0, Average accuracy: {'gsm8k_cot': {'exact_match,strict-match': 0.0, 'exact_match_stderr,strict-match': 0.0, 'exact_match,flexible-extract': 0.013333333333333334, 'exact_match_stderr,flexible-extract': 0.006633137535414957, 'alias': 'gsm8k_cot'}, 'piqa': {'acc,none': 0.53, 'acc_stderr,none': 0.02886365132641709, 'acc_norm,none': 0.5233333333333333, 'acc_norm_stderr,none': 0.028884243402038653, 'alias': 'piqa'}, 'arc_challenge': {'acc,none': 0.19333333333333333, 'acc_stderr,none': 0.02283835560647653, 'acc_norm,none': 0.22333333333333333, 'acc_norm_stderr,none': 0.024085657867318557, 'alias': 'arc_challenge'}, 'winogrande': {'acc,none': 0.5133333333333333, 'acc_stderr,none': 0.02890546361555505, 'alias': 'winogrande'}, 'hellaswag': {'acc,none': 0.2966666666666667, 'acc_stderr,none': 0.02641674975105534, 'acc_norm,none': 0.35333333333333333, 'acc_norm_stderr,none': 0.027643749490906887, 'alias': 'hellaswag'}, 'arc_easy': {'acc,none': 0.36333333333333334, 'acc_stderr,none': 0.027814616968981958, 'acc_norm,none': 0.35333333333333333, 'acc_norm_stderr,none': 0.027643749490906887, 'alias': 'arc_easy'}}
